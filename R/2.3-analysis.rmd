This file generates all plots and tables for final analysis and visualization 
of the projects results.

```{r, libraries}
library(ggplot2)
library(ggpubr)
library(viridis)
library(dplyr)
library(terra)
library(tidyterra)
library(rnaturalearth)
library(sf)
library(factoextra)
library(magick)
library(png)
library(grid)
library(gridExtra)
source("R/0.0-functions.r", encoding = "UTF-8") # self written functions used
```

```{r}
# used colour hex codes:
c("#00ba38", "#f8766d", "#3f80f1")
ftheme <- theme(
    legend.title = element_text(size = 15), legend.key.size = unit(1, "cm"),
    legend.text = element_text(size = 14), axis.title = element_text(size = 14)
)
```

```{r, plot presence yearly count 2002-2022}
occs <- readRDS("R/data/occurrence_data/axyridis_clean.rds")
cat("presences before 2002:", nrow(subset(occs, Year < 2002)), "\n")
occs <- subset(occs, Year >= 2002)
data_eu <- as.data.frame(table(subset(occs, Area == "eu")$Year))
data_eu$Area <- "eu"
data_as <- as.data.frame(table(subset(occs, Area == "as")$Year))
data_as$Area <- "as"
data <- merge(data_eu, data_as, by = "Var1", all.x = TRUE)
data[is.na(data)] <- 0
data$Area.y <- "as"
data_eu <- data[, c(1, 2, 3)]
data_as <- data[, c(1, 4, 5)]
names(data_eu) <- c("Year", "Freq", "Area")
names(data_as) <- names(data_eu)
data <- rbind(data_eu, data_as)

p <- ggplot(data, aes(x = Year, y = Freq, fill = Area)) +
    geom_point(aes(colour = Area, shape = Area), size = 2.5) +
    geom_line(aes(colour = Area, group = Area)) +
    scale_y_log10() +
    scale_color_manual(values = c("#00ba38", "#f8766d")) +
    scale_x_discrete(breaks = seq(2002, 2022, by = 4)) +
    labs(x = "Year", y = "Number of Observations") +
    theme_pubr() +
    ftheme
ggsave(p, width = 8, height = 5, filename = "R/figures/pres-per-year-log.png")
```

```{r, plot comparison raw dataset to cleaned}
# use equal earth crs? greyscale?
raw <- read.csv("R/data/occurrence_data/Harmonia-axyridis_gbif_raw.csv",
    header = TRUE,
    sep = "\t"
)
clean <- readRDS("R/data/occurrence_data/axyridis_clean.rds")
cat("raw:", nrow(raw), "|clean:", nrow(clean), "\n")
raw <- raw[!(raw$decimalLongitude %in% clean$Lon) & !(raw$decimalLatitude %in% clean$Lat), ]
lc_ref <- rast("R/data/cropped_rasters/Cop_LC_2002_eu.tif")

raw_v <- vect(raw, geom = c("decimalLongitude", "decimalLatitude"), crs = crs(lc_ref))
clean_v <- vect(clean, geom = c("Lon", "Lat"), crs = crs(lc_ref))
exts_v <- vect(ext(lc_ref), crs = crs(lc_ref))
lc_ref <- rast("R/data/cropped_rasters/Cop_LC_2002_as.tif")
exts_v <- rbind(exts_v, vect(ext(lc_ref), crs = crs(lc_ref)))
# countries map
countries <- ne_countries(scale = "medium", returnclass = "sf")
countries <- st_transform(countries, crs = crs(lc_ref))
countries <- vect(countries)

# plot
p <- ggplot(countries) +
    geom_spatvector(colour = "black", fill = "white") +
    geom_spatvector(data = raw_v, colour = "#3f80f1") +
    geom_spatvector(data = subset(clean_v, clean_v$Area == "eu"), colour = "#f8766d") +
    geom_spatvector(data = exts_v[1], colour = "#f8766d", fill = NA, linetype = "solid", linewidth = 1) +
    geom_spatvector(data = subset(clean_v, clean_v$Area == "as"), colour = "#00ba38") +
    geom_spatvector(data = exts_v[2], colour = "#00ba38", fill = NA, linetype = "solid", linewidth = 1) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    theme_pubr()
ggsave(p, width = 8, height = 5, filename = "R/figures/raw-vs-cleaned-glob.png")
```

```{r, plot extent subdiv method and pa example}
ext0 <- c(0, 15, 0, 10)
set.seed(4236)
# sample 20 random points to subdivide
pts <- vect(spatSample(ext(ext0), 30, lonlat = TRUE))
subexts <- lp_subdiv_pts(pts, 5, ext0)
# bias by resampling a bit in one sub extent
for (i in 1:2) {
    pts <- rbind(pts[-5, ], vect(spatSample(ext(subexts[nrow(subexts) - 1, ]), 5, lonlat = TRUE)))
    subexts <- lp_subdiv_pts(pts, 10, ext0) # subdivide with 30% threshold
}

# generate 3 absences per presence
n <- 3
# one third without subdivision
pts_gen1 <- vect(spatSample(ext(ext0), 1 * nrow(pts), lonlat = TRUE))
# two thirds with subdivision for bias correction
pts_gen2 <- vect(spatSample(ext(ext0), 1, lonlat = TRUE)) # initialize
for (e in seq_len(nrow(subexts))) {
    pts_in <- crop(pts, ext(subexts[e, ]))
    pts_g <- vect(spatSample(ext(subexts[e, ]), 2 * nrow(pts_in), lonlat = TRUE))
    pts_gen2 <- rbind(pts_gen2, pts_g)
}
pts_gen2 <- pts_gen2[-1, ]

# plot
p1 <- ggplot() +
    geom_spatvector(data = pts_gen1, size = 2, shape = 1) +
    geom_spatvector(data = pts_gen2, size = 2, shape = 8) +
    geom_spatvector(data = pts, size = 2, colour = "#00ba38") +
    theme_pubr() +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x.bottom = element_blank(), axis.line.y.left = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
for (i in seq_len(nrow(subexts))) {
    p1 <- p1 + geom_spatvector(data = vect(ext(subexts[i, ])), colour = "#3f80f1", fill = NA, linetype = "solid", linewidth = 0.5)
}

# pa subdiv example with 2008
pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
lc_ref <- rast("R/data/cropped_rasters/Cop_LC_2002_eu.tif")

pa <- subset(pa, Area == "eu" & Year == 2008)
pa_v <- vect(pa, geom = c("Lon", "Lat"), crs = crs(lc_ref))

# countries map
countries <- ne_countries(scale = "medium", returnclass = "sf")
countries <- st_transform(countries, crs = crs(lc_ref))
countries <- vect(countries)

p2 <- ggplot(crop(countries, ext(lc_ref))) +
    geom_spatvector(colour = "black", fill = "white") +
    geom_spatvector(data = subset(pa_v, pa_v$Presence == "absent"), colour = "grey", size = 1) +
    geom_spatvector(data = subset(pa_v, pa_v$Presence == "present"), colour = "#00ba38", size = 1) +
    theme_pubr()
subexts <- readRDS("R/data/plotting/axyridis_abs_gen_subexts.rds")
for (i in seq_len(nrow(subexts))) {
    p2 <- p2 + geom_spatvector(data = vect(ext(subexts[i, ]), crs = crs(lc_ref)), colour = "#3f80f1", fill = NA, linetype = "solid", linewidth = 0.5)
}
p <- ggarrange(p1, p2, ncol = 1, labels = c("A", "B"), font.label = list(size = 20))
ggsave(p, width = 6, height = 7, bg = "white", filename = "R/figures/ext-subdiv.png")
```

```{r, combine some niche year plots into one figure}
years <- c("20022003", "20122013", "20212022")
p <- list()
for (i in seq_len(length(years))) {
    p[[i]] <- image_read(paste0("R/plots/niche_comp/single_ys/eu_", years[i], "_niche.png"))
}

img <- image_append(c(p[[1]], p[[2]]))
img <- image_append(c(img, p[[3]]))
image_write(img, path = "R/figures/eu-niche-ys.png", format = "png")
```

```{r, plot of eu niche dynamic indices over time}
# get niche dynamic results + overlap per year
dyn <- as.data.frame(readRDS("R/data/modelling/niche_y_dynamic.rds"))
ol <- readRDS("R/data/modelling/niche_y_overlap.rds")
colnames(ol) <- "overlap"
years <- 2002:2020
dyn <- cbind(years, head(dyn, length(years)), head(ol, length(years)))
# convert to long format
long_dyn <- data.frame()
for (i in 1:4) {
    di <- dyn[, c(1, i + 1)]
    di$index <- colnames(dyn)[i + 1]
    colnames(di)[2] <- "value"
    long_dyn <- rbind(long_dyn, di)
}
long_dyn$index <- factor(long_dyn$index, levels = colnames(dyn)[2:5]) # fix order

p <- ggplot(data = long_dyn, aes(x = years, y = value, color = index, shape = index)) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = c("#f8766d", "#619cff", "#00ba38", "black")) +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    theme_pubr() +
    ftheme

ggsave(p, width = 8, height = 5, filename = "R/figures/eu-niche-dyn.png")
```

```{r, create variable table with VIFs}
vifs <- readRDS("R/data/modelling/var_select_vifs.rds")

vars <- data.frame(matrix(ncol = nrow(vifs), nrow = 0))
vars <- rbind(vars, round(vifs[, 1], digits = 2))
colnames(vars) <- as.list(gsub(".*s\\((.+)\\)*.", "\\1", rownames(vifs))) # no s()
Name <- "VIF"
vars <- cbind(Name, vars)

# write to .csv for table
write.csv(vars, file = "Latex/mainthesis/tab-var-vifs.csv", row.names = FALSE, quote = FALSE)
```

```{r, plot sdm performance over time}
years <- 2002:2020

# get tpr for each year
tpr_fy <- data.frame(year = years) # initialize tpr dataframe
for (y in years) {
    eval <- readRDS(paste0("R/data/modelling/eval_mods/eval_mod_", y, ".rds")) # read eval
    for (m in 1:5) { # get tpr for each model
        # fy tpr df
        ev <- eval[1, ]
        tpr_fy[y - 2001, m + 1] <- ev[[m]]$sensitivity
        colnames(tpr_fy)[m + 1] <- ev[[m]]$model
    }
}
# save tpr results
mod_tpr_res <- cbind(tpr_fy)
saveRDS(mod_tpr_res, file = "R/data/modelling/mod_tpr_res.rds")

# convert to long format
long_fy <- data.frame()
for (m in 1:5) {
    # fy tpr
    tpr_m <- tpr_fy[, c(1, m + 1)]
    tpr_m$model <- colnames(tpr_m)[2]
    colnames(tpr_m)[2] <- "tpr"
    long_fy <- rbind(long_fy, tpr_m)
}

# get tpr for each year with native model
rnt <- readRDS("R/data/modelling/eval_mods/eval_mod_native.rds")
# get tpr for each year
tpr_nt <- data.frame(year = years) # initialize tpr dataframe
for (y in years) {
    eval <- rnt[paste(y), ] # read eval
    for (m in 1:5) { # get tpr for each model
        tpr_nt[y - 2001, m + 1] <- eval[[m]]$sensitivity
        colnames(tpr_nt)[m + 1] <- eval[[m]]$model
    }
}
# save tpr results for native
saveRDS(tpr_nt, file = "R/data/modelling/mod_tpr_res_nat.rds")

# convert to long format
long_nt <- data.frame()
for (m in 1:5) {
    # fy tpr
    tpr_m <- tpr_nt[, c(1, m + 1)]
    tpr_m$model <- colnames(tpr_m)[2]
    colnames(tpr_m)[2] <- "tpr"
    long_nt <- rbind(long_nt, tpr_m)
}

p1 <- ggplot(data = long_fy, aes(x = year, y = tpr, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    theme_pubr() +
    ftheme

p2 <- ggplot(data = long_nt, aes(x = year, y = tpr, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    theme_pubr() +
    ftheme

p <- ggarrange(p1, p2, nrow = 2, common.legend = TRUE, labels = "AUTO", font.label = list(size = 20))
ggsave(p, width = 8, height = 8, bg = "white", filename = "R/figures/modelling-res.png")
```

```{r, correlation model performance with pcount or niche dyn}
tpr_res <- readRDS("R/data/modelling/mod_tpr_res.rds")
dyn <- readRDS("R/data/modelling/niche_y_dynamic.rds")
nvar <- as.data.frame(dyn)$stability
nvar <- nvar[1:19]

# get list of total pa points up to year in EU
pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
eu <- subset(pa, Area == "eu")
pcount <- c()
for (i in 2002:2022) {
    pcount[i - 2001] <- nrow(subset(eu, Year <= i))
}
# pcount for years used
pcount <- head(pcount, length(nvar))

# compute pearson correlation for each model
cor_res <- c()
for (i in 2:6) {
    tpr_mod <- tpr_res[, i]
    c_ol <- cor.test(tpr_mod, nvar, method = "pearson")
    c_pc <- cor.test(tpr_mod, pcount, method = "pearson")
    c_res_mod <- c(c_ol$estimate, c_ol$p.value, c_pc$estimate, c_pc$p.value)
    cor_res <- cbind(cor_res, c_res_mod)
}
cor_res <- round(cor_res, digits = 3)
rownames(cor_res) <- NULL
colnames(cor_res) <- colnames(tss_res)[2:6]
cor_res <- cbind(Model = c("Correlation niche stability", "p-value", "Correlation data count", "p-value"), cor_res)

write.csv(cor_res, file = "Latex/mainthesis/tab-mod-cor-res.csv", row.names = FALSE, quote = FALSE)
```

```{r, tss of native on training data}
rnt <- readRDS("R/data/modelling/eval_mods/eval_mod_native.rds")
# get tss for trained
eval <- rnt["trained", ]

# if entry NA (no ensemble possible) compute tss = 0
if (any(is.na(eval))) {
    na <- which(is.na(eval))
    eval[[na]]$sensitivity <- 0.5
    eval[[na]]$specificity <- 0.5
    eval[[na]]$model <- "ens"
}
tss_t <- data.frame(data = "trained")
for (m in 1:5) { # get tss for each model
    # tss df
    tss_t[1, m + 1] <- eval[[m]]$sensitivity + eval[[m]]$specificity - 1
    colnames(tss_t)[m + 1] <- eval[[m]]$model
}
print(tss_t)
```

```{r, plot all modelling results}
years <- 2002:2020

# get tss for each year
tss_fy <- data.frame(year = years) # initialize tss dataframe
tss_22 <- tss_fy
tss_t <- tss_fy
for (y in years) {
    eval <- readRDS(paste0("R/data/modelling/eval_mods/eval_mod_", y, ".rds")) # read eval
    # if entry NA (no ensemble possible) compute tss = 0
    if (any(is.na(eval))) {
        na <- which(is.na(eval))
        eval[[na]]$sensitivity <- 0.5
        eval[[na]]$specificity <- 0.5
        eval[[na]]$model <- "ens"
    }
    for (m in 1:5) { # get tss for each model
        # fy tss df
        ev <- eval[1, ]
        tss_fy[y - 2001, m + 1] <- ev[[m]]$sensitivity #+ ev[[m]]$specificity - 1
        colnames(tss_fy)[m + 1] <- ev[[m]]$model
        # 2022 tss df
        ev <- eval[2, ]
        tss_22[y - 2001, m + 1] <- ev[[m]]$sensitivity #+ ev[[m]]$specificity - 1
        colnames(tss_22)[m + 1] <- ev[[m]]$model
        # trained tss df
        ev <- eval[3, ]
        tss_t[y - 2001, m + 1] <- ev[[m]]$sensitivity #+ ev[[m]]$specificity - 1
        colnames(tss_t)[m + 1] <- ev[[m]]$model
    }
}
# save tss results
mod_tss_res <- cbind(tss_fy, tss_22, tss_t)
saveRDS(mod_tss_res, file = "R/data/modelling/mod_tss_res.rds")

# convert to long format
long_fy <- data.frame()
long_22 <- data.frame()
long_t <- data.frame()
for (m in 1:5) {
    # fy tss
    tss_m <- tss_fy[, c(1, m + 1)]
    tss_m$model <- colnames(tss_m)[2]
    colnames(tss_m)[2] <- "tss"
    long_fy <- rbind(long_fy, tss_m)
    # 2022 tss
    tss_m <- tss_22[, c(1, m + 1)]
    tss_m$model <- colnames(tss_m)[2]
    colnames(tss_m)[2] <- "tss"
    long_22 <- rbind(long_22, tss_m)
    # trained tss
    tss_m <- tss_t[, c(1, m + 1)]
    tss_m$model <- colnames(tss_m)[2]
    colnames(tss_m)[2] <- "tss"
    long_t <- rbind(long_t, tss_m)
}

# get tss for each year with native model
rnt <- readRDS("R/data/modelling/eval_mods/eval_mod_native.rds")
# get tss for each year
tss_nt <- data.frame(year = years) # initialize tss dataframe
for (y in years) {
    eval <- rnt[paste(y), ] # read eval
    # if entry NA (no ensemble possible) compute tss = 0
    if (any(is.na(eval))) {
        na <- which(is.na(eval))
        eval[[na]]$sensitivity <- 0.5
        eval[[na]]$specificity <- 0.5
        eval[[na]]$model <- "ens"
    }
    for (m in 1:5) { # get tss for each model
        # fy tss df
        tss_nt[y - 2001, m + 1] <- eval[[m]]$sensitivity #+ eval[[m]]$specificity - 1
        colnames(tss_nt)[m + 1] <- eval[[m]]$model
    }
}
# save tss results for native
saveRDS(tss_nt, file = "R/data/modelling/mod_tss_res_nat.rds")

# convert to long format
long_nt <- data.frame()
for (m in 1:5) {
    # fy tss
    tss_m <- tss_nt[, c(1, m + 1)]
    tss_m$model <- colnames(tss_m)[2]
    colnames(tss_m)[2] <- "tss"
    long_nt <- rbind(long_nt, tss_m)
}

# get total pa points up to year in eu
pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
pa <- subset(pa, Year >= 2002)
eu <- subset(pa, Area == "eu")
pa_count <- data.frame()
for (i in tss_fy$year) {
    pa_y <- c(i, nrow(subset(eu, Year <= i)))
    pa_count <- rbind(pa_count, pa_y)
}
colnames(pa_count) <- c("year", "pa_count")

# get niche dynamic results + overlap per year
dyn <- as.data.frame(readRDS("R/data/modelling/niche_y_dynamic.rds"))
ol <- readRDS("R/data/modelling/niche_y_overlap.rds")
colnames(ol) <- "overlap"
dyn <- cbind(years, head(dyn, length(years)), head(ol, length(years)))
# convert to long format
long_dyn <- data.frame()
for (i in 1:4) {
    di <- dyn[, c(1, i + 1)]
    di$index <- colnames(dyn)[i + 1]
    colnames(di)[2] <- "value"
    long_dyn <- rbind(long_dyn, di)
}
long_dyn$index <- factor(long_dyn$index, levels = colnames(dyn)[2:5]) # fix order

# plot
p1 <- ggplot(data = pa_count, aes(x = years, y = pa_count)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years))) +
    ggtitle("Total pa-data count up to year in EU") +
    theme_pubr()
p2 <- ggplot(data = long_dyn, aes(x = years, y = value, color = index, shape = index)) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = c("#f8766d", "#619cff", "#00ba38", "black")) +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    ggtitle("niche dynamic indices for invasive niche (year compared to previous)") +
    theme_pubr()
p3 <- ggplot(data = long_nt, aes(x = year, y = tss, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    ggtitle("tss for predicting the following year (native data model)") +
    theme_pubr()
p4 <- ggplot(data = long_t, aes(x = year, y = tss, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    ggtitle("tss for predicting the trained dataset") +
    theme_pubr()
p5 <- ggplot(data = long_fy, aes(x = year, y = tss, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    ggtitle("tss for predicting year (invasive data model)") +
    theme_pubr()
p6 <- ggplot(data = long_22, aes(x = year, y = tss, color = model, shape = model)) +
    geom_point() +
    geom_line() +
    coord_cartesian(xlim = c(2002, max(years)), ylim = c(0, 1)) +
    ggtitle("tss for predicting 2022 (invasive data model)") +
    theme_pubr()

p <- ggarrange(p1, p2, p3, p4, p5, p6, nrow = 2, ncol = 3, labels = "AUTO")
ggsave(p, width = 15, height = 6, bg = "white", filename = "R/figures/modelling-res.png")
```

```{r, plot detailed model results for all years}
library(PresenceAbsence)

# print confusion matrix for 2005, 2010, 2015, 2020 ensemble predicting fy
res <- data.frame()
for (y in 2002:2020) {
    th_data <- readRDS(paste0("R/data/modelling/th_data_mods/th_data_m", y, "_", y + 1, ".rds"))
    eval <- readRDS(paste0("R/data/modelling/eval_mods/eval_mod_", y, ".rds"))
    ens_res <- eval[1, 5][[1]] # look at ensemble results
    cmx <- cmx(th_data, threshold = ens_res$threshold, which.model = 5)
    eval <-
        tss <- ens_res$sensitivity + ens_res$specificity - 1
    n <- nrow(th_data) # for relative amount
    res_y <- c(y, cmat[1, 1] / n, cmat[1, 2] / n, cmat[2, 1] / n, cmat[2, 2] / n, ens_res$sensitivity, ens_res$specificity, tss)
    res <- rbind(res, res_y)
}
colnames(res) <- c("year", "tpos", "fpos", "fneg", "tneg", "sens", "spec", "tss")

res_long <- data.frame()
for (i in seq_len(ncol(res) - 1)) {
    rlong <- res[, c(1, i + 1)]
    rlong$measure <- colnames(res)[i + 1]
    colnames(rlong)[2] <- "value"
    res_long <- rbind(res_long, rlong)
}

p <- ggplot(data = res_long, aes(x = year, y = value, colour = measure, shape = measure)) +
    geom_point() +
    geom_line() +
    theme_pubr()
ggsave(p, filename = "R/plots/model_performance_detail.png")
```

```{r, plot ens prediction suitability viridis}
y <- 2020 # year cutoff for model data
y_pred <- 2022 # year to predict for
th_data <- readRDS(paste0("R/data/modelling/th_data_mods/th_data_m", y, "_", y_pred, ".rds"))

pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
pa_ext <- readRDS("R/data/occurrence_data/axyridis_pa_vals_extracted.rds")
po <- subset(pa, Area == "eu" & Year == y_pred & Presence == "present")
pa <- subset(pa, Area == "eu" & Year == y_pred & Presence == "absent")
lc_ref <- rast("R/data/cropped_rasters/Cop_LC_2002_eu.tif")
pa_ext <- subset(pa_ext, Area == "eu" & Year == y_pred & Presence == "absent")
th_data <- subset(th_data, pres == 0)
ext_join <- data.frame(Lon = pa_ext$Lon, Lat = pa_ext$Lat, Prob_ens = th_data$ens)

pa_m <- left_join(pa, ext_join)
pa_m <- slice_head(pa_m, n = round(nrow(pa_m) / 3))
pa_m <- pa_m[complete.cases(pa_m), ]
pa_v <- vect(pa_m, geom = c("Lon", "Lat"), crs = crs(lc_ref))
po_v <- vect(po, geom = c("Lon", "Lat"), crs = crs(lc_ref))

# countries map
countries <- ne_countries(scale = "medium", returnclass = "sf")
countries <- st_transform(countries, crs = crs(lc_ref))
countries <- vect(countries)

# plot with suitability value
p <- ggplot(crop(countries, ext(lc_ref))) +
    geom_spatvector(colour = "black", fill = "white") +
    geom_spatvector(data = pa_v, aes(color = Prob_ens)) +
    scale_color_viridis() +
    # geom_spatvector(data = po_v) +
    labs(color = "suitability") +
    ggtitle(paste0(y, " ens prediction for ", y_pred, " suitability values"))
fname <- paste0("R/plots/ens_20suitability22.png")
ggexport(p, width = 800, height = 600, filename = fname)
```

```{r, test correlation tss ol and pc}
tss_res <- readRDS("R/data/modelling/mod_tss_res.rds")
dyn <- readRDS("R/data/modelling/niche_y_dynamic.rds")
overlaps <- as.data.frame(dyn)$stability
overlaps <- overlaps[1:19]

# get list of total pa points up to year in EU
pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
eu <- subset(pa, Area == "eu")
pcount <- c()
for (i in 2002:2022) {
    pcount[i - 2001] <- nrow(subset(eu, Year <= i))
}
# pcount for years used
pcount <- head(pcount, length(overlaps))

# compute pearson correlation for tss_fy
cor_res <- data.frame(row.names = c("ol_c", "ol_p", "pc_c", "pc_p"))
for (i in 2:6) {
    tss_mod <- tss_res[, i]
    c_ol <- cor.test(overlaps, tss_mod, method = "pearson")
    # plot(tss_mod, overlaps, main = colnames(tss_res)[i])
    c_pc <- cor.test(pcount, tss_mod, method = "pearson")
    # plot(tss_mod, pcount,  main = colnames(tss_res)[i])
    c_res_mod <- c(c_ol$estimate, c_ol$p.value, c_pc$estimate, c_pc$p.value)
    cor_res <- cbind(cor_res, c_res_mod)
}
colnames(cor_res) <- colnames(tss_res)[2:6]
# correlate pcount and ol
cor_pc_ol <- data.frame(row.names = c("02-20", "02-07", "08-20"))
c_pc_ol <- cor.test(pcount, overlaps, method = "pearson")
res_pc_ol <- c(c_pc_ol$estimate, c_pc_ol$p.value)
cor_pc_ol <- rbind(cor_pc_ol, res_pc_ol)
colnames(cor_pc_ol) <- c("corr.", "p value")
p1 <- ggtexttable(signif(cor_res, digits = 4))

# compute again but only until 2007
overlaps2 <- head(overlaps, 6)
pcount2 <- head(pcount, 6)
cor_res <- data.frame(row.names = c("ol_c", "ol_p", "pc_c", "pc_p"))
for (i in 2:6) {
    tss_mod <- tss_res[seq_along(overlaps) + 1, i]
    tss_mod2 <- head(tss_mod, 6)
    c_ol <- cor.test(overlaps2, tss_mod2, method = "pearson")
    # plot(tss_mod, overlaps, main = colnames(tss_res)[i])
    c_pc <- cor.test(pcount2, tss_mod2, method = "pearson")
    # plot(tss_mod, pcount,  main = colnames(tss_res)[i])
    c_res_mod <- c(c_ol$estimate, c_ol$p.value, c_pc$estimate, c_pc$p.value)
    cor_res <- cbind(cor_res, c_res_mod)
}
colnames(cor_res) <- colnames(tss_res)[2:6]
# correlate pcount and ol
c_pc_ol <- cor.test(pcount2, overlaps2, method = "pearson")
res_pc_ol <- c(c_pc_ol$estimate, c_pc_ol$p.value)
cor_pc_ol <- rbind(cor_pc_ol, res_pc_ol)
colnames(cor_pc_ol) <- c("corr.", "p value")
p2 <- ggtexttable(signif(cor_res, digits = 4))

# compute again but only starting from 2008
overlaps2 <- tail(overlaps, -6)
pcount2 <- tail(pcount, -6)
cor_res <- data.frame(row.names = c("ol_c", "ol_p", "pc_c", "pc_p"))
for (i in 2:6) {
    tss_mod <- tss_res[seq_along(overlaps) + 1, i]
    tss_mod2 <- tail(tss_mod, -6)
    c_ol <- cor.test(overlaps2, tss_mod2, method = "pearson")
    # plot(tss_mod, overlaps, main = colnames(tss_res)[i])
    c_pc <- cor.test(pcount2, tss_mod2, method = "pearson")
    # plot(tss_mod, pcount,  main = colnames(tss_res)[i])
    c_res_mod <- c(c_ol$estimate, c_ol$p.value, c_pc$estimate, c_pc$p.value)
    cor_res <- cbind(cor_res, c_res_mod)
}
colnames(cor_res) <- colnames(tss_res)[2:6]
# correlate pcount and ol
c_pc_ol <- cor.test(pcount2, overlaps2, method = "pearson")
res_pc_ol <- c(c_pc_ol$estimate, c_pc_ol$p.value)
cor_pc_ol <- rbind(cor_pc_ol, res_pc_ol)
colnames(cor_pc_ol) <- c("pc to ol corr.", "p value")
rownames(cor_pc_ol) <- c("02-20", "02-07", "08-20")
p3 <- ggtexttable(signif(cor_res, digits = 4))
p4 <- ggtexttable(signif(cor_pc_ol, digits = 4))
p <- ggarrange(p1, p2, p3, p4, nrow = 4, ncol = 1, labels = c("02-20", "02-07", "08-20")) + bgcolor("white")
ggsave(p, width = 5, height = 8, filename = "R/plots/cor_ol-pc_res.png")
```

```{r, create niche gif for invaded range}
# list file names and read in
imgs <- list.files("R/plots/niche_comp/single_ys/", full.names = TRUE)
img_list <- lapply(imgs, image_read)
img_joined <- image_join(img_list)
img_animated <- image_animate(img_joined, fps = 2)

# save gif
image_write(
    image = img_animated,
    path = "R/plots/niche_comp/eu_yearstoprev_niche.gif"
)
```



```{r, correlation tests using regression}
dyn <- as.data.frame(readRDS("R/data/modelling/niche_y_dynamic.rds"))
ol <- readRDS("R/data/modelling/niche_y_overlap.rds")
tss_res <- readRDS("R/data/modelling/mod_tss_res.rds")

# get list of total pa points up to year in EU
pa <- readRDS("R/data/occurrence_data/axyridis_pa.rds")
eu <- subset(pa, Area == "eu")
pcount <- c()
for (i in 2002:2022) {
    pcount[i - 2001] <- nrow(subset(eu, Year <= i))
}

tss_ens <- tss_res[seq_along(ol), 6]
data <- data.frame(tss_ens, pcount, ol, dyn)
data <- head(data, 19) # due to NA after 2019

# fit glm
glm <- glm(tss_ens ~ ., data = data, family = gaussian)
summary(glm)

glm <- glm(tss_ens ~ pcount, data = data, family = gaussian)
summary(glm)

glm <- glm(tss_ens ~ stability, data = data, family = gaussian)
summary(glm)
```

```{r, plot var select pca results}
lc_pca <- readRDS("R/data/modelling/var_select_lc_pca_res.rds")
# plot pca results
# png(width = 1800, height = 600, filename = "R/plots/var_select_lc_pca.png")
p1 <- fviz_pca(lc_pca)
p2 <- fviz_screeplot(lc_pca)
# p3 <- ggplot(pa_ext, aes(x = lccs_class)) +
#    geom_histogram() +
#    scale_x_continuous(breaks = sort(unique(pa_ext$lccs_class)))
ggarrange(p1, p2, nrow = 1)
# dev.off()
```

```{r, plot niche eq and sim results for a year}
y <- 2003 # starts with 2003, max 2022 (05)
eq_test <- readRDS("R/data/modelling/niche_y_eq_sim.rds")[y - 2002, 2]
sim_test <- readRDS("R/data/modelling/niche_y_eq_sim.rds")[y - 2002, 3]

# fname <- paste0("R/plots/niche_comp/single_ys/eu_", y - 1, y, "_eq-sim.png")
# png(width = 1200, height = 600, filename = fname)
par(mfrow = c(1, 2))
# plot eq_test
ecospat.plot.overlap.test(eq_test, "D", paste("Equivalency", y - 1, "/", y))
# plot sim_test
ecospat.plot.overlap.test(sim_test, "D", paste("Similarity", y - 1, "/", y))
# dev.off()
```

```{r, compute mean lc heterogeneity}
pa_vals <- readRDS("R/data/occurrence_data/axyridis_pa_vals_extracted.rds")
pa_vals <- subset(pa_vals, Area == "eu" & Presence == "present")


sh_ent <- function(row) {
    return(-sum(row * log(row), na.rm = TRUE)) # which log to use (values larger than one)
}
het_mean_ys <- c()
for (y in unique(pa_vals$Year)) { # unique(pa_vals$Year)
    rlc_y <- select(subset(pa_vals, Year == y), starts_with("lc"))
    lc_het <- apply(rlc_y, 1, sh_ent)
    het_mean <- mean(lc_het)
    het_mean_ys <- c(het_mean_ys, het_mean)
}
print(het_mean_ys)
print(-log(1 / ncol(rlc_y))) # max value for heterogeneity
print(het_mean_ys / (-log(1 / ncol(rlc_y)))) # heterogeneity as value relative to max
```
